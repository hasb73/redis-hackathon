# Architecture Diagram - Redis VL Log Analysis System

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         HDFS Log Sources                             â”‚
â”‚                    (DataNode, NameNode, etc.)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     Kafka      â”‚
                    â”‚  Topic: logs   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Spark Streaming Job                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ 1. Read from Kafka                                           â”‚  â”‚
â”‚  â”‚ 2. Normalize log (strip IPs, blocks, etc.)                  â”‚  â”‚
â”‚  â”‚ 3. Check Redis for existing pattern                         â”‚  â”‚
â”‚  â”‚ 4. If new pattern:                                           â”‚  â”‚
â”‚  â”‚    - Generate embedding via Embedding Service               â”‚  â”‚
â”‚  â”‚    - Store in Redis VL                                       â”‚  â”‚
â”‚  â”‚ 5. If duplicate: Skip (save costs!)                         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                               â”‚
             â–¼                               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Embedding    â”‚            â”‚   Redis Stack    â”‚
    â”‚    Service     â”‚            â”‚   (Redis VL)     â”‚
    â”‚  Port: 8000    â”‚            â”‚   Port: 6379     â”‚
    â”‚                â”‚            â”‚                  â”‚
    â”‚ - Model:       â”‚            â”‚ - Vector Index   â”‚
    â”‚   sentence-    â”‚            â”‚ - KNN Search     â”‚
    â”‚   transformers â”‚            â”‚ - 384-dim        â”‚
    â”‚ - 384-dim      â”‚            â”‚ - COSINE metric  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                                           â”‚
                                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Log Analysis Chat Service                        â”‚
â”‚                         Port: 8004                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ User Query â†’ Extract Intent â†’ Generate Embedding             â”‚  â”‚
â”‚  â”‚                                                               â”‚  â”‚
â”‚  â”‚ Vector Search in Redis VL:                                   â”‚  â”‚
â”‚  â”‚   FT.SEARCH logs_embeddings                                  â”‚  â”‚
â”‚  â”‚   *=>[KNN 5 @embedding $vec AS score]                        â”‚  â”‚
â”‚  â”‚                                                               â”‚  â”‚
â”‚  â”‚ Return: Top 5 similar logs with similarity scores            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Web Browser   â”‚
                    â”‚  User Interfaceâ”‚
                    â”‚                â”‚
                    â”‚ - Chat UI      â”‚
                    â”‚ - WebSocket    â”‚
                    â”‚ - Suggestions  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Data Flow Examples

### Example 1: New Log Pattern

```
1. HDFS Log:
   "Receiving block blk_-1608999687919862906 src: /10.250.19.102:54106"
   
2. Spark Normalizes:
   "Receiving block <BLOCK_ID> src: /<IP>:<PORT>"
   
3. Check Redis:
   normalized:abc123 â†’ NOT FOUND
   
4. Generate Embedding:
   POST /embed â†’ [0.123, -0.456, 0.789, ...]
   
5. Store in Redis:
   log_entry:xyz789 â†’ {
     text: "Receiving block blk_-1608...",
     embedding: <384-dim vector>,
     normalized_text: "Receiving block <BLOCK_ID>...",
     label: 0,
     timestamp: "2025-10-28T12:00:00"
   }
   normalized:abc123 â†’ "log_entry:xyz789" (expires in 30 days)
```

### Example 2: Duplicate Log Pattern

```
1. HDFS Log:
   "Receiving block blk_-9999999999999999999 src: /10.250.10.6:40524"
   
2. Spark Normalizes:
   "Receiving block <BLOCK_ID> src: /<IP>:<PORT>"
   
3. Check Redis:
   normalized:abc123 â†’ FOUND! (points to log_entry:xyz789)
   
4. Skip Embedding:
   â­ï¸  No embedding generated (cost saved!)
   
5. Log Skipped:
   "Skipped 1 duplicate log patterns already in Redis"
```

### Example 3: User Query

```
1. User Types:
   "Find logs similar to receiving block"
   
2. Chat Service:
   - Extract intent: "similar_logs"
   - Extract keywords: "receiving block"
   
3. Generate Query Embedding:
   POST /embed â†’ [0.125, -0.450, 0.792, ...]
   
4. Vector Search:
   FT.SEARCH logs_embeddings
   *=>[KNN 5 @embedding $query_vec AS score]
   SORTBY score
   
5. Results:
   [
     {log: "Receiving block blk_123...", score: 0.945},
     {log: "Receiving block blk_456...", score: 0.932},
     {log: "Received block blk_789...", score: 0.891},
     {log: "DataNode receiving blk_...", score: 0.876},
     {log: "Block reception started...", score: 0.854}
   ]
   
6. Format Response:
   "ğŸ” Found 5 Similar Logs:
    1. âœ… Receiving block blk_123... (Similarity: 0.945)
    2. âœ… Receiving block blk_456... (Similarity: 0.932)
    ..."
```

## ğŸ“Š Redis VL Schema

### Index Structure
```
Index: logs_embeddings
Prefix: log_entry:
Fields:
  - text: TEXT (original log message)
  - embedding: VECTOR (384-dim, FLOAT32, COSINE)
  - label: NUMERIC (0=normal, 1=anomaly)
  - timestamp: TEXT (ISO format)
  - normalized_text: TEXT (pattern template)
```

### Data Storage
```
Redis Keys:

1. Log Entries (permanent):
   log_entry:abc123 â†’ HASH {
     text: "Receiving block blk_123...",
     embedding: <binary vector>,
     label: 0,
     timestamp: "2025-10-28T12:00:00",
     normalized_text: "Receiving block <BLOCK_ID>...",
     log_level: "INFO",
     source: "hdfs_datanode"
   }

2. Normalized Patterns (30-day expiry):
   normalized:xyz789 â†’ "log_entry:abc123"
   TTL: 2592000 seconds (30 days)
```

## ğŸ¯ Key Components

### 1. Spark Job (`spark/spark_job.py`)
- **Input:** Kafka topic "logs"
- **Processing:** Normalize, deduplicate, embed
- **Output:** Redis VL entries
- **Trigger:** Every 10 seconds

### 2. Embedding Service (`embedding_service/app.py`)
- **Model:** sentence-transformers/all-MiniLM-L6-v2
- **Dimensions:** 384
- **Endpoint:** POST /embed
- **Input:** {"texts": ["log message"]}
- **Output:** {"embeddings": [[0.123, ...]]}

### 3. Chat Service (`log-analysis-chat/app.py`)
- **Frontend:** HTML/JavaScript (WebSocket + HTTP)
- **Backend:** FastAPI (Python)
- **Features:**
  - Natural language query understanding
  - Vector similarity search
  - System health monitoring
  - Performance metrics

### 4. Redis Stack
- **Redis VL:** Vector storage and search
- **RedisInsight:** Web UI (port 8001)
- **Features:**
  - FT.SEARCH for vector queries
  - KNN algorithm
  - COSINE distance metric

## ğŸ”§ Configuration

### Environment Variables
```bash
# Spark Job
KAFKA_SERVERS=localhost:9092
KAFKA_TOPICS=logs
EMBEDDING_SERVICE_URL=http://localhost:8000/embed
REDIS_HOST=localhost
REDIS_PORT=6379

# Chat Service
REDIS_STACK_HOST=redis-stack
EMBEDDING_SERVICE_URL=http://embedding:8000
DB_PATH=/app/anomaly-detection-service/anomaly_detection.db
```

### Docker Compose Ports
```yaml
- Kafka: 9092
- Zookeeper: 2181
- Redis Stack: 6379 (Redis), 8001 (RedisInsight)
- Redis AI: 6380
- Embedding: 8000
- Chat: 8004
- Grafana: 3000
```

## ğŸ“ˆ Performance Metrics

### Embedding Generation
- **Time:** ~50ms per embedding
- **Reduction:** 80-90% with deduplication
- **Cost:** Significant savings

### Vector Search
- **Time:** ~10-20ms for KNN search
- **Results:** Top 5 similar logs
- **Accuracy:** High semantic similarity

### System Throughput
- **Spark:** Processes batches every 10 seconds
- **Chat:** Real-time responses via WebSocket
- **Redis:** Sub-millisecond lookups

## ğŸ‰ Benefits

1. **Cost Reduction:** 80-90% fewer embedding calls
2. **Fast Search:** Vector similarity in milliseconds
3. **Natural Language:** Query logs conversationally
4. **Scalable:** Handles millions of logs
5. **Real-time:** WebSocket for instant responses
6. **Intelligent:** Semantic understanding of logs

---

**Status:** Production Ready âœ…
